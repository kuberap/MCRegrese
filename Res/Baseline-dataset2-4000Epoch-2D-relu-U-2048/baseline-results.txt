
EPOCHS = 4000  # 00  # pocet epoch pro uceni
LR = 0.001  # 0.0001
BATCH = 4096
DEEP = 2
UNITS = 2048
DROPOUT = 0.1

Epoch 4000/4000
12/12 - 0s - loss: 0.0495 - mse: 0.0050 - mae: 0.0372 - val_loss: 0.0408 - val_mse: 0.0044 - val_mae: 0.0285 - 269ms/epoch - 22ms/step
1688/1688 [==============================] - 4s 2ms/step
188/188 [==============================] - 0s 1ms/step
TRAIN>>>0.0042112101268997415
CORR:0.9857281630304261
CORR:0.9362199668913985
CORR:0.9829847691575356
CORR:0.9925489834105228
TEST>>>0.004295119918989695
CORR:0.9850885464299746
CORR:0.9332565217181927
CORR:0.985011708046495
CORR:0.9919143152499209


***********************************************************
nejlepsi vysledek na tomto modelu pro 1000 epoch s upravenou mae funkci - pouzito logaritmovani y
LOSS SLOPE:-1.3299335365427043e-05
TRAIN MSE SCALED:0.0032123107509420554
CORR:0.9878884929353772
CORR:0.940278006979238
CORR:0.9878346696658763
CORR:0.9955346942641121
TEST MSE SCALED:0.003203944065368322
CORR:0.9873694654803719
CORR:0.9369531081960824
CORR:0.9885280697389872
CORR:0.995130917834952

**************************************************************************
zmena learning rate a epoch

EPOCHS = 10000  # 00  # pocet epoch pro uceni

IN_DIM = 21
OUT_DIM = 4
LR = 0.0001  # 0.001
BATCH = 4096

# parametry modelu
DEEP = 2
UNITS = 512
DROPOUT = 0.1

LOSS SLOPE:-1.2168955204408485e-06
TRAIN MSE SCALED:0.002412118098378056
CORR:0.9902194791833445
CORR:0.9497007552454387
CORR:0.9910372454692072
CORR:0.9979901047090715
TEST MSE SCALED:0.0023938211876523645
CORR:0.9897497544661418
CORR:0.9475912063498663
CORR:0.9914656711794206
CORR:0.9977075778136746



